#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
01_data_loading_and_analysis.py
ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°, ë³‘í•© ë° êµ¬ì¡° ë¶„ì„ í†µí•© ìŠ¤í¬ë¦½íŠ¸
ì‘ì„±ì¼: 2025-01-08
Python ë³€í™˜: 2025-01-18
"""

import os
import sys
import glob
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple

# ========== íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ==========
import pandas as pd
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT))

# ========== í™˜ê²½ ì„¤ì • ==========
class Config:
    """í”„ë¡œì íŠ¸ ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.project_root = PROJECT_ROOT
        self.raw_data_path = self.project_root / "data" / "raw_data"
        self.processed_data_path = self.project_root / "data" / "processed"
        self.reports_path = self.project_root / "reports"
        
        # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
        self._create_directories()
    
    def _create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        for path in [self.processed_data_path, self.reports_path]:
            path.mkdir(parents=True, exist_ok=True)
            print(f"í´ë” í™•ì¸/ìƒì„±: {path}")
    
    def generate_filename(self, prefix: str, name: str, extension: str) -> str:
        """íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ íŒŒì¼ëª… ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"{timestamp}_{name}.{extension}"


# ========== ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ==========
class DataLoader:
    """Excel ë°ì´í„° ë¡œë”© ë° ë³‘í•© í´ë˜ìŠ¤"""
    
    def __init__(self, config: Config):
        self.config = config
        
    def find_excel_files(self) -> List[Path]:
        """raw_data í´ë”ì˜ ëª¨ë“  Excel íŒŒì¼ ì°¾ê¸°"""
        pattern1 = str(self.config.raw_data_path / "*.xls")
        pattern2 = str(self.config.raw_data_path / "*.xlsx")
        
        files = glob.glob(pattern1) + glob.glob(pattern2)
        file_paths = [Path(f) for f in files]
        
        print(f"ë°œê²¬ëœ íŒŒì¼ ê°œìˆ˜: {len(file_paths)}")
        print("íŒŒì¼ ëª©ë¡:")
        for f in file_paths:
            print(f" - {f.name}")
        
        return file_paths
    
    def load_excel_file(self, file_path: Path) -> pd.DataFrame:
        """Excel íŒŒì¼ ì½ê¸°"""
        print(f"\níŒŒì¼ ì½ê¸°: {file_path.name}")
        
        # Excel íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        excel_file = pd.ExcelFile(file_path)
        sheet_names = excel_file.sheet_names
        print(f"ì‹œíŠ¸ ê°œìˆ˜: {len(sheet_names)}")
        print(f"ì‹œíŠ¸ ì´ë¦„: {', '.join(sheet_names)}")
        
        # ì²« ë²ˆì§¸ ì‹œíŠ¸ ì½ê¸°
        df = pd.read_excel(file_path, sheet_name=0)
        
        # íŒŒì¼ëª…ì„ ë°ì´í„°ì— ì¶”ê°€ (ì¶œì²˜ ì¶”ì ìš©)
        df['source_file'] = file_path.name
        
        return df
    
    def load_and_combine(self) -> Optional[pd.DataFrame]:
        """ëª¨ë“  Excel íŒŒì¼ ë¡œë“œ ë° ë³‘í•©"""
        print("========== ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹œì‘ ==========")
        
        file_list = self.find_excel_files()
        
        if not file_list:
            print("raw_data í´ë”ì— Excel íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        if len(file_list) == 1:
            # ë‹¨ì¼ íŒŒì¼
            combined_data = self.load_excel_file(file_list[0])
        else:
            # ì—¬ëŸ¬ íŒŒì¼ ë³‘í•©
            print("\nì—¬ëŸ¬ íŒŒì¼ ë³‘í•© ì¤‘...")
            data_frames = [self.load_excel_file(f) for f in file_list]
            combined_data = pd.concat(data_frames, ignore_index=True)
        
        # ğŸ› ë””ë²„ê·¸ í¬ì¸íŠ¸: ë°ì´í„° ë¡œë“œ ì™„ë£Œ í›„ í™•ì¸
        print(f"DEBUG: ë°ì´í„° shape = {combined_data.shape}")  # ë¸Œë ˆì´í¬í¬ì¸íŠ¸ ì¶”ì²œ
        
        return combined_data


# ========== ë°ì´í„° ë¶„ì„ í•¨ìˆ˜ ==========
class DataAnalyzer:
    """ë°ì´í„° êµ¬ì¡° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, config: Config):
        self.config = config
    
    def standardize_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë°ì´í„° í‘œì¤€í™” (ì»¬ëŸ¼ëª… ì •ë¦¬ ë“±)"""
        # ì»¬ëŸ¼ëª… ì •ë¦¬: ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜ ë“±
        df.columns = df.columns.str.strip()
        return df
    
    def analyze_structure(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ë°ì´í„° êµ¬ì¡° ë¶„ì„"""
        print("\n========== ë°ì´í„° êµ¬ì¡° ë¶„ì„ ==========")
        
        # ê¸°ë³¸ ì •ë³´
        total_rows = len(df)
        total_cols = len(df.columns)
        column_names = df.columns.tolist()
        column_types = df.dtypes.to_dict()
        
        print(f"ì „ì²´ í–‰ ìˆ˜: {total_rows:,}")
        print(f"ì „ì²´ ì—´ ìˆ˜: {total_cols}")
        
        # ì—´ ì •ë³´ ìƒì„¸ ë¶„ì„
        print("\n========== ì—´ ì •ë³´ ìƒì„¸ ==========")
        
        column_info = pd.DataFrame({
            'ë²ˆí˜¸': range(1, len(column_names) + 1),
            'ì—´ì´ë¦„': column_names,
            'ë°ì´í„°íƒ€ì…': [str(dtype) for dtype in df.dtypes],
            'ê²°ì¸¡ì¹˜ìˆ˜': df.isna().sum().values,
            'ê²°ì¸¡ì¹˜ë¹„ìœ¨': [f"{(cnt/total_rows*100):.2f}%" for cnt in df.isna().sum()],
            'ê³ ìœ ê°’ìˆ˜': [df[col].nunique() for col in column_names]
        })
        
        print(column_info.to_string(index=False))
        
        # í…ìŠ¤íŠ¸ ì—´ ì‹ë³„ (í˜•íƒœì†Œ ë¶„ì„ ëŒ€ìƒ)
        text_columns = [col for col in column_names 
                       if df[col].dtype == 'object' and col != 'source_file']
        
        print("\ní…ìŠ¤íŠ¸ ì—´ (í˜•íƒœì†Œ ë¶„ì„ ê°€ëŠ¥):")
        for col in text_columns:
            non_na_values = df[col].dropna()
            if len(non_na_values) > 0:
                sample_text = str(non_na_values.iloc[0])
                if len(sample_text) > 20:
                    sample_text = sample_text[:20] + "..."
                print(f" - {col}: '{sample_text}'")
        
        # ë°ì´í„° ìƒ˜í”Œ
        print("\n========== ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5í–‰) ==========")
        print(df.iloc[:5, :min(5, len(df.columns))])
        
        # ë¶„ì„ ê²°ê³¼ ë°˜í™˜
        return {
            'total_rows': total_rows,
            'total_cols': total_cols,
            'column_info': column_info,
            'text_columns': text_columns,
            'sample_data': df.head(10),
            'analysis_date': datetime.now().strftime("%Y-%m-%d")
        }
    
    def save_results(self, df: pd.DataFrame, analysis: Dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        print("\n========== ë°ì´í„° ì €ì¥ ==========")
        
        # íŒŒì¼ëª… ìƒì„±
        rds_filename = self.config.generate_filename("", "combined_data", "parquet")
        csv_filename = self.config.generate_filename("", "combined_data", "csv")
        info_filename = self.config.generate_filename("", "data_structure_info", "json")
        
        # ë°ì´í„° ì €ì¥
        df.to_parquet(self.config.processed_data_path / rds_filename)
        df.to_csv(self.config.processed_data_path / csv_filename, 
                 index=False, encoding='utf-8-sig')
        
        # ë¶„ì„ ì •ë³´ ì €ì¥ (JSONìœ¼ë¡œ)
        import json
        
        # DataFrameì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        analysis_json = analysis.copy()
        analysis_json['column_info'] = analysis['column_info'].to_dict('records')
        analysis_json['sample_data'] = analysis['sample_data'].to_dict('records')
        
        with open(self.config.processed_data_path / info_filename, 'w', encoding='utf-8') as f:
            json.dump(analysis_json, f, ensure_ascii=False, indent=2)
        
        # Markdown ë³´ê³ ì„œ ìƒì„±
        report_filename = self.config.generate_filename("", "data_structure_summary", "md")
        self._create_markdown_report(analysis, report_filename)
        
        print(f"\nì™„ë£Œ! ë‹¤ìŒ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(f"- ë°ì´í„°: {self.config.processed_data_path / rds_filename}")
        print(f"- CSV: {self.config.processed_data_path / csv_filename}")
        print(f"- ë¶„ì„ ì •ë³´: {self.config.processed_data_path / info_filename}")
        print(f"- ë³´ê³ ì„œ: {self.config.reports_path / report_filename}")
        
        return {
            'data_file': str(self.config.processed_data_path / rds_filename),
            'csv_file': str(self.config.processed_data_path / csv_filename),
            'info_file': str(self.config.processed_data_path / info_filename),
            'report_file': str(self.config.reports_path / report_filename)
        }
    
    def _create_markdown_report(self, analysis: Dict[str, Any], filename: str):
        """Markdown ë³´ê³ ì„œ ìƒì„±"""
        report_lines = [
            "# ë°ì´í„° êµ¬ì¡° ë¶„ì„ ë³´ê³ ì„œ (ìë™ ìƒì„±)\n",
            f"**ë¶„ì„ì¼**: {analysis['analysis_date']}",
            "**ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸**: 01_data_loading_and_analysis.py\n",
            "## ë°ì´í„° ìš”ì•½",
            f"- ì „ì²´ í–‰ ìˆ˜: {analysis['total_rows']:,}",
            f"- ì „ì²´ ì—´ ìˆ˜: {analysis['total_cols']}\n",
            "## í˜•íƒœì†Œ ë¶„ì„ ê°€ëŠ¥ í…ìŠ¤íŠ¸ ì—´"
        ]
        
        for col in analysis['text_columns']:
            report_lines.append(f"- {col}")
        
        report_lines.extend([
            "\n## ì—´ ì •ë³´ ìš”ì•½",
            "| ì—´ ì´ë¦„ | ë°ì´í„° íƒ€ì… | ê²°ì¸¡ì¹˜ ë¹„ìœ¨ | ê³ ìœ ê°’ ìˆ˜ |",
            "|---------|------------|------------|----------|"
        ])
        
        for _, row in analysis['column_info'].iterrows():
            if row['ì—´ì´ë¦„'] != 'source_file':
                report_lines.append(
                    f"| {row['ì—´ì´ë¦„']} | {row['ë°ì´í„°íƒ€ì…']} | "
                    f"{row['ê²°ì¸¡ì¹˜ë¹„ìœ¨']} | {row['ê³ ìœ ê°’ìˆ˜']:,} |"
                )
        
        with open(self.config.reports_path / filename, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))


# ========== ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ==========
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì • ì´ˆê¸°í™”
    config = Config()
    
    # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
    loader = DataLoader(config)
    
    # ë°ì´í„° ë¡œë“œ ë° ë³‘í•©
    combined_data = loader.load_and_combine()
    
    if combined_data is None:
        return
    
    # ë°ì´í„° ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = DataAnalyzer(config)
    
    # ë°ì´í„° í‘œì¤€í™”
    combined_data = analyzer.standardize_data(combined_data)
    
    # ë°ì´í„° êµ¬ì¡° ë¶„ì„
    analysis_result = analyzer.analyze_structure(combined_data)
    
    # ê²°ê³¼ ì €ì¥
    saved_files = analyzer.save_results(combined_data, analysis_result)
    
    return combined_data, analysis_result, saved_files


if __name__ == "__main__":
    # ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ
    combined_data, analysis_result, saved_files = main()