---
marp: true
theme: default
size: 16:9
paginate: true
---

# **R을 활용한 고품질 텍스트 분석**
## Bareun 형태소 분석기 활용 및 복합어 처리 전략

---

# 강의 목표 및 목차

## 강의 목표
- R에서 Bareun 형태소 분석기를 설정하고 사용하는 방법을 이해한다.
- 텍스트 데이터에서 유의미한 복합어를 추출하는 통계적 기법을 학습한다.
- 분석 품질을 높이기 위한 사용자 사전 구축 및 활용 프로세스를 익힌다.

## 목차
1. **Intro:** 왜 형태소 분석과 복합어 처리가 중요한가?
2. **Part 1:** Bareun 형태소 분석기 활용법 (`02_0`, `02_1` 스크립트 기반)
3. **Part 2:** 통계적 복합어 처리 기법 (`03_0` 스크립트 기반)
4. **Wrap-up:** 전체 프로세스 요약 및 Q&A

---

# Part 1: Bareun 형태소 분석기 활용법

---

# Bareun 형태소 분석기란?

## 개요
- 최신 자연어 처리 기술을 기반으로 하는 한국어 형태소 분석기
- gRPC 통신을 사용하여 Docker 환경에서 서버 형태로 구동
- R에서는 `RBareun` 또는 `bareun` 패키지를 통해 API 방식으로 연동

## 주요 특징
- **빠른 분석 속도**: 서버-클라이언트 구조로 대용량 데이터 처리 용이
- **사용자 사전**: 도메인 특화 용어(신조어, 복합어)를 추가하여 분석 정확도 향상 가능
- **안정성**: `tryCatch` 구문을 활용한 에러 핸들링으로 대규모 문서 분석 시 중단 방지

---

# 분석 프로세스 개요 (`02_0_abstract_morpheme_analysis.R`)

1.  **환경 설정**
    -   `Sys.setenv(BAREUN_API_KEY = 'YOUR_KEY')`로 API 키 설정
    -   `library(RBareun)` 등 필요 패키지 로드

2.  **데이터 로드**
    -   `readRDS()`로 분석할 데이터(`merged_data.rds`) 로드
    -   분석 대상 텍스트 컬럼 지정 (예: `국문 초록 (Abstract)`)

3.  **Bareun 서버 및 사전 설정**
    -   `setup_dictionary_and_bareun()` 함수 실행
    -   사용할 사용자 사전(Domain)을 대화형으로 선택
    -   `tagger()` 객체를 생성하여 분석기 준비

4.  **핵심 분석 실행: 명사 추출**
    -   `extract_nouns_with_metadata()` 함수 호출
    -   내부적으로 `nouns()` 함수를 사용하여 각 문서에서 명사만 추출
    -   (개선 포인트) 2글자 이상 명사만 필터링, 에러 발생 시 빈 결과로 처리

5.  **결과 저장**
    -   `save_analysis_results_with_metadata()` 함수 실행
    -   **단어 빈도**: `abstract_word_frequency.csv`
    -   **문서별 명사 리스트**: `abstract_documents_with_nouns.csv`
    -   **R 객체**: `abstract_analysis_complete.rds` (가장 중요)

---

# 핵심 코드 리뷰: `extract_nouns_with_metadata()`

## 주요 로직
- 문서(초록) 목록을 `for` 루프로 순회
- `preprocess_abstract()`: 간단한 전처리 (공백, 줄바꿈 제거)
- `nouns(tagger, text)`: Bareun API를 호출하여 명사 추출
- `nchar(noun) >= 2`: 추출된 명사 중 2글자 이상만 필터링
- `doc_results` 리스트에 문서 ID, 원문, 메타데이터, 추출된 명사 목록을 함께 저장

## 에러 처리의 중요성
- `tryCatch` 블록을 사용하여 특정 문서 분석에 실패하더라도 전체 스크립트가 중단되지 않도록 방지
- 오류 발생 시, 해당 문서는 명사가 없는(`character(0)`) 결과로 저장하여 데이터 구조의 일관성 유지

---

# Part 2: 통계적 복합어 처리 기법

---

# 복합어, 왜 중요한가?

## 문제점
- "머신러닝 기반 예측 모델" → `머신러닝`, `기반`, `예측`, `모델` (X)
- 위와 같이 분리되면 "머신러닝 모델", "예측 모델" 등 핵심 단어의 의미가 희석됨
- 도메인 전문 용어는 일반 사전에 없어 복합어로 인식되지 못함

## 해결 전략
- 텍스트의 통계적 특성을 이용해 유의미한 단어 뭉치(복합어 후보)를 발굴
- 발굴된 후보를 사용자 사전에 추가하여 분석 품질을 향상시키는 **피드백 루프** 구축

---

# 복합어 후보 발굴 기법 (`03_0_...and_compounds.R`)

## 1. N-gram 분석
- **개념**: 연속적으로 나타나는 N개의 단어 뭉치
- **방법**: `unnest_tokens(ngram, ...)` 또는 스크립트의 수동 구현
- **장점**: 구현이 간단하고 직관적임
- **단점**: 단순 빈도에만 의존하여 우연히 자주 나타나는 조합도 후보가 됨
- *스크립트 함수: `perform_ngram_analysis()`*

## 2. 연어(Collocation) 분석
- **개념**: 특정 단어들이 우연 이상의 확률로 함께 나타나는 경향
- **측정 지표**: **PMI (Pointwise Mutual Information)** 점수
    - `PMI = log( P(w1, w2) / (P(w1) * P(w2)) )`
    - 두 단어가 독립적으로 나타날 확률 대비, 함께 나타날 확률이 얼마나 높은지 측정
- **장점**: 단순 빈도보다 통계적으로 유의미한 조합을 찾는데 효과적
- *스크립트 함수: `perform_collocation_analysis()`*

---

# 사용자 설정 기능: Window Size

## Window Size (윈도우 크기)란?
- 연어 분석 시, 한 단어를 기준으로 주변 몇 개 단어까지를 연관 단어로 볼 것인지 결정하는 범위
- **Window Size = 2**: 바로 다음에 오는 단어만 고려 (A B, B C)
- **Window Size = 5**: 기준 단어의 다음 4개 단어까지 모두 연관 쌍으로 고려 (A B, A C, A D, A E)

## 설정 방법 (`get_analysis_settings` 함수)
- 스크립트 실행 시, 사용자에게 `readline()`을 통해 윈도우 크기를 입력받음
- 이 값을 `perform_collocation_analysis` 함수에 전달하여 분석의 유연성 확보

---

# 후보 선정 및 사전 구축 프로세스

1.  **후보 생성**: N-gram과 연어 분석을 통해 대량의 후보 리스트 생성

2.  **품질 평가**: `evaluate_candidate_quality()`
    - 빈도, 문서 분포, PMI, 길이, 키워드 포함 여부 등을 종합하여 각 후보에 **품질 점수** 부여
    - A+ ~ D 등급으로 분류하여 우선순위 결정

3.  **사용자 검토 (Human-in-the-loop)**
    - 점수가 높은 후보들을 `compound_word_candidates_EDIT_ME.csv` 파일로 생성
    - 분석가가 직접 파일을 열어 진짜 복합어로 사용할 것들만 남기고 나머지는 삭제

4.  **사전 파일 생성**: `03_1_create_bareun_user_dict.R`
    - 사용자가 편집한 CSV 파일을 읽어 Bareun 사용자 사전 형식(단어\tNNP)의 `.tsv` 파일로 변환

5.  **사전 등록**: `00_bareun_dictionary_manager.R`
    - 생성된 `.tsv` 파일을 Bareun 서버에 `dict_upload()` 함수로 업로드

---

# 전체 워크플로우 및 피드백 루프

- **(1차 분석)**
    - `02_0...` 스크립트로 기본 명사 추출

- **(복합어 발굴)**
    - `03_0...` 스크립트로 1차 분석 결과에서 복합어 후보 생성 및 `EDIT_ME.csv` 파일 생성

- **(사전 구축)**
    - 사용자가 `EDIT_ME.csv` 편집
    - `03_1...` 스크립트로 편집된 파일을 Bareun 사전 파일(`.tsv`)로 변환
    - `00_...` 스크립트로 Bareun 서버에 신규 사전 업로드

- **(2차 분석)**
    - `02_0...` 스크립트를 **다시 실행**하되, 이번에는 새로 업로드한 사용자 사전을 선택

- **결과**: "머신러닝 기반"과 같은 복합어가 하나의 명사로 인식되어 분석의 질적 향상

---

# 결론 및 Q&A

## Key Takeaways
- 고품질 텍스트 분석의 시작은 잘 정제된 형태소 분석 결과로부터 나옴
- Bareun 분석기의 사용자 사전은 도메인 특화 분석의 핵심 기능
- N-gram, PMI 등 통계적 방법과 분석가의 수동 검토를 결합하는 것이 복합어 처리의 효과적인 전략

## Q&A
