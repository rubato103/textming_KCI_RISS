```markdown
---
marp: true
theme: default
size: 16:9
paginate: true
---

# **R을 활용한 고품질 텍스트 분석**
## Bareun 형태소 분석기 활용법

---

# 강의 목표 및 목차

## 강의 목표
- R에서 Bareun 형태소 분석기를 설정하고 사용하는 방법을 이해한다.
- 분석 품질을 높이기 위한 사용자 사전 구축 및 활용 프로세스를 익힌다.

## 목차
1. **Intro:** 왜 형태소 분석이 중요한가?
2. **Part 1:** Bareun 형태소 분석기 활용법
3. **Wrap-up:** 요약 및 Q&A

---

# Part 1: Bareun 형태소 분석기 활용법

---

# Bareun 형태소 분석기란?

## 개요
- 최신 자연어 처리 기술을 기반으로 하는 한국어 형태소 분석기
- gRPC 통신을 사용하여 Docker 환경에서 서버 형태로 구동
- R에서는 `RBareun` 또는 `bareun` 패키지를 통해 API 방식으로 연동

## 주요 특징
- **빠른 분석 속도**: 서버-클라이언트 구조로 대용량 데이터 처리 용이
- **사용자 사전**: 도메인 특화 용어(신조어, 복합어)를 추가하여 분석 정확도 향상 가능
- **안정성**: `tryCatch` 구문을 활용한 에러 핸들링으로 대규모 문서 분석 시 중단 방지

---

# 다양한 형태소 분석기 비교

---

# 형태소 분석기의 진화

## 전통적 방식에서 딥러닝 기반으로
- **전통적 사전·규칙 기반**: Mecab-ko, Komoran, Hannanum, Kkma
    - 미리 구축된 사전과 규칙에 의존
    - 처리 속도가 빠르지만, 신조어/비표준어 처리 및 정확도 한계
- **딥러닝·신경망 기반**: Khaiii, Kiwi, Nori, Bareun
    - 대규모 말뭉치 학습을 통해 문맥을 이해하고 형태소 분석 수행
    - 높은 정확도와 유연성, 신조어/비표준어 대응력 우수

---

# 전통적 사전·규칙 기반 분석기

## Mecab-ko (은전한닢)
- **특징**: 압도적인 처리 속도 (초당 20만 어절), 경량 메모리 (50MB)
- **장점**: 대규모 실시간 처리에 최적화
- **단점**: 정확도 85% 수준으로 상대적으로 낮음

## Komoran (코모란)
- **특징**: Java 기반 구현, Java 생태계 통합 용이
- **성능**: 정확도 93%, 초당 3만 어절 처리
- **단점**: 반복 문장 처리 시 속도 저하 발생 가능

## Hannanum (한나눔) & Kkma (꼬꼬마)
- **특징**: 구문 분석 기능 포함, 정교한 분석 가능
- **Kkma 성능**: 정확도 95%로 높지만, 초당 1천 어절 처리 속도로 대규모 데이터 처리 한계

---

# 딥러닝 기반 분석기

## Khaiii (카카오)
- **특징**: 2018년 최초 딥러닝 기반 분석기, CNN 기술 적용
- **성능**: 94% 정확도, GPU 없이도 비교적 빠른 처리 가능

## Kiwi (키위)
- **특징**: 통계적 언어모델과 Skip-Bigram 결합, 모호성 해소에 강점
- **Kiwi CoNg (2025.5)**: Transformer 기반 신경망 모델 도입
- **성능**: 웹 텍스트 87%, 문어 텍스트 94% 정확도, 초당 7만 어절 처리

## Nori (Elasticsearch)
- **특징**: 검색 엔진 최적화 특화, Elasticsearch 공식 지원
- **성능**: 초당 약 5만 문서 처리, 정확도 95% 이상

## Bareun (바른)
- **특징**: 2023년 2월 공동 개발, **뉴스 데이터 특화** (7,800만 건 뉴스 기사 학습)
- **핵심 기술**: 딥러닝과 규칙 기반의 하이브리드 접근법, Transformer 모델 활용
- **성능**: **현존 최고 수준의 정확도 (품사 태깅 99.6%, 어절 분리 99.7%)**

---

# 성능 비교 요약: 정확도

## 정확도 순위 (2025년 7월 기준)
1.  **Bareun (99.6%)**
2.  Kkma (95%) = Kiwi CoNg (95%) = Nori (95%)
3.  Khaiii (94%) = Kiwi (94%)
4.  Komoran (93%)
5.  Okt (88%)
6.  Hannanum (87%)
7.  Mecab-ko (85%)

- **Bareun의 압도적 정확도**: 대규모 뉴스 데이터 학습과 한국어 특성을 반영한 106개 분절 규칙의 효과

---

# 성능 비교 요약: 속도 및 메모리

## 처리 속도 순위 (어절/초, CPU 기준)
1.  Mecab-ko (20만)
2.  Kiwi CoNg (7만)
3.  Kiwi (5만) = Nori (5만)
4.  **Bareun (4만)**
5.  Komoran (3만)
6.  Okt (2.5만)
7.  Khaiii (1만)
8.  Hannanum (5천)
9.  Kkma (1천)

## 메모리 효율성 (MB)
- **가장 효율적**: Mecab-ko (50MB)
- **딥러닝 기반 분석기**: 높은 정확도를 위해 더 많은 메모리 사용 (Bareun 350MB, Kiwi CoNg 360MB)

---

# 실무 적용 가이드라인

## 용도별 추천 분석기
| 요구사항         | 추천 분석기       | 근거                                     |
| :--------------- | :---------------- | :--------------------------------------- |
| 초고속 실시간 처리 | Mecab-ko, Nori    | 초당 20만 어절 처리, 경량 메모리         |
| 최고 정확도 요구 | Bareun, Kkma      | 99.6%, 95% 정확도                        |
| 뉴스·언론 분야   | Bareun            | 뉴스 데이터 특화 학습                    |
| 웹·커뮤니티 텍스트 | Kiwi, Okt         | 웹 텍스트 87% 정확도, 신조어 대응        |
| Java 생태계 통합 | Komoran, Nori     | Java 네이티브 구현                       |
| 구문 분석 병행   | Kkma, Hannanum    | 품사·의존 구문 정보 제공                 |

## 하이브리드 접근법
- 단일 분석기보다는 여러 분석기를 조합하는 것이 효과적
- 예: 초기 대량 처리는 Mecab-ko, 정밀 분석이 필요한 부분은 Bareun으로 처리

---

# 미래 전망

## 형태소 분석 기술의 발전 방향
- **Transformer 융합**: 문맥 이해도 및 정확도 향상
- **도메인 특화 모델**: 특정 분야 데이터에 최적화된 분석기 등장
- **경량화 기술**: 고성능 유지하며 메모리/속도 효율 개선
- **멀티모달 처리**: 텍스트 외 이미지, 음성 등 복합 데이터 분석
- **실시간 학습**: 분석기가 스스로 학습하며 성능 개선
- **LLM (거대 언어 모델) 통합**: 새로운 한국어 처리 패러다임 제시

---

# 분석 프로세스 개요 (`02_0_abstract_morpheme_analysis.R`)

1.  **환경 설정**
    -   `Sys.setenv(BAREUN_API_KEY = 'YOUR_KEY')`로 API 키 설정
    -   `library(RBareun)` 등 필요 패키지 로드

2.  **데이터 로드**
    -   `readRDS()`로 분석할 데이터(`merged_data.rds`) 로드
    -   분석 대상 텍스트 컬럼 지정 (예: `국문 초록 (Abstract)`)

3.  **Bareun 서버 및 사전 설정**
    -   `setup_dictionary_and_bareun()` 함수 실행
    -   사용할 사용자 사전(Domain)을 대화형으로 선택
    -   `tagger()` 객체를 생성하여 분석기 준비

4.  **핵심 분석 실행: 명사 추출**
    -   `extract_nouns_with_metadata()` 함수 호출
    -   내부적으로 `nouns()` 함수를 사용하여 각 문서에서 명사만 추출
    -   (개선 포인트) 2글자 이상 명사만 필터링, 에러 발생 시 빈 결과로 처리

5.  **결과 저장**
    -   `save_analysis_results_with_metadata()` 함수 실행
    -   **단어 빈도**: `abstract_word_frequency.csv`
    -   **문서별 명사 리스트**: `abstract_documents_with_nouns.csv`
    -   **R 객체**: `abstract_analysis_complete.rds` (가장 중요)

---

# 핵심 코드 리뷰: `extract_nouns_with_metadata()`

## 주요 로직
- 문서(초록) 목록을 `for` 루프로 순회
- `preprocess_abstract()`: 간단한 전처리 (공백, 줄바꿈 제거)
- `nouns(tagger, text)`: Bareun API를 호출하여 명사 추출
- `nchar(noun) >= 2`: 추출된 명사 중 2글자 이상만 필터링
- `doc_results` 리스트에 문서 ID, 원문, 메타데이터, 추출된 명사 목록을 함께 저장

## 에러 처리의 중요성
- `tryCatch` 블록을 사용하여 특정 문서 분석에 실패하더라도 전체 스크립트가 중단되지 않도록 방지
- 오류 발생 시, 해당 문서는 명사가 없는(`character(0)`) 결과로 저장하여 데이터 구조의 일관성 유지

---

# 결론 및 Q&A

## Key Takeaways
- 고품질 텍스트 분석의 시작은 잘 정제된 형태소 분석 결과로부터 나옴
- Bareun 분석기의 사용자 사전은 도메인 특화 분석의 핵심 기능
- 다양한 형태소 분석기의 특징과 성능을 이해하고 목적에 맞게 선택하는 것이 중요

## Q&A
