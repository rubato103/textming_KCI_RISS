---
marp: true
theme: default
size: 16:9
paginate: true
---

# **R을 활용한 고품질 텍스트 분석**
## 복합어 처리 기법

---

# 강의 목표 및 목차

## 강의 목표
- 텍스트 데이터에서 유의미한 복합어를 추출하는 통계적 기법을 학습한다.
- 분석 품질을 높이기 위한 사용자 사전 구축 및 활용 프로세스를 익힌다.

## 목차
1. **Intro:** 왜 복합어 처리가 중요한가?
2. **Part 1:** 통계적 복합어 처리 기법
3. **Wrap-up:** 전체 프로세스 요약 및 Q&A

---

# Part 1: 통계적 복합어 처리 기법

---

# 복합어, 왜 중요한가?

## 문제점
- "머신러닝 기반 예측 모델" → `머신러닝`, `기반`, `예측`, `모델` (X)
- 위와 같이 분리되면 "머신러닝 모델", "예측 모델" 등 핵심 단어의 의미가 희석됨
- 도메인 전문 용어는 일반 사전에 없어 복합어로 인식되지 못함

## 해결 전략
- 텍스트의 통계적 특성을 이용해 유의미한 단어 뭉치(복합어 후보)를 발굴
- 발굴된 후보를 사용자 사전에 추가하여 분석 품질을 향상시키는 **피드백 루프** 구축

---

# 복합어 후보 발굴 기법 (`03_0_...and_compounds.R`)

## 1. N-gram 분석
- **개념**: 연속적으로 나타나는 N개의 단어 뭉치
- **방법**: `unnest_tokens(ngram, ...)` 또는 스크립트의 수동 구현
- **장점**: 구현이 간단하고 직관적임
- **단점**: 단순 빈도에만 의존하여 우연히 자주 나타나는 조합도 후보가 됨
- *스크립트 함수: `perform_ngram_analysis()`*

## 2. 연어(Collocation) 분석
- **개념**: 특정 단어들이 우연 이상의 확률로 함께 나타나는 경향
- **측정 지표**: **PMI (Pointwise Mutual Information)** 점수
    - `PMI = log( P(w1, w2) / (P(w1) * P(w2)) )`
    - 두 단어가 독립적으로 나타날 확률 대비, 함께 나타날 확률이 얼마나 높은지 측정
- **장점**: 단순 빈도보다 통계적으로 유의미한 조합을 찾는데 효과적
- *스크립트 함수: `perform_collocation_analysis()`*

---

# 사용자 설정 기능: Window Size

## Window Size (윈도우 크기)란?
- 연어 분석 시, 한 단어를 기준으로 주변 몇 개 단어까지를 연관 단어로 볼 것인지 결정하는 범위
- **Window Size = 2**: 바로 다음에 오는 단어만 고려 (A B, B C)
- **Window Size = 5**: 기준 단어의 다음 4개 단어까지 모두 연관 쌍으로 고려 (A B, A C, A D, A E)

## 설정 방법 (`get_analysis_settings` 함수)
- 스크립트 실행 시, 사용자에게 `readline()`을 통해 윈도우 크기를 입력받음
- 이 값을 `perform_collocation_analysis` 함수에 전달하여 분석의 유연성 확보

---

# 후보 선정 및 사전 구축 프로세스

1.  **후보 생성**: N-gram과 연어 분석을 통해 대량의 후보 리스트 생성

2.  **품질 평가**: `evaluate_candidate_quality()`
    - 빈도, 문서 분포, PMI, 길이, 키워드 포함 여부 등을 종합하여 각 후보에 **품질 점수** 부여
    - A+ ~ D 등급으로 분류하여 우선순위 결정

3.  **사용자 검토 (Human-in-the-loop)**
    - 점수가 높은 후보들을 `compound_word_candidates_EDIT_ME.csv` 파일로 생성
    - 분석가가 직접 파일을 열어 진짜 복합어로 사용할 것들만 남기고 나머지는 삭제

4.  **사전 파일 생성**: `03_1_create_bareun_user_dict.R`
    - 사용자가 편집한 CSV 파일을 읽어 Bareun 사용자 사전 형식(단어\tNNP)의 `.tsv` 파일로 변환

5.  **사전 등록**: `00_bareun_dictionary_manager.R`
    - 생성된 `.tsv` 파일을 Bareun 서버에 `dict_upload()` 함수로 업로드

---

# 전체 워크플로우 및 피드백 루프

- **(1차 분석)**
    - `02_0...` 스크립트로 기본 명사 추출

- **(복합어 발굴)**
    - `03_0...` 스크립트로 1차 분석 결과에서 복합어 후보 생성 및 `EDIT_ME.csv` 파일 생성

- **(사전 구축)**
    - 사용자가 `EDIT_ME.csv` 편집
    - `03_1...` 스크립트로 편집된 파일을 Bareun 사전 파일(`.tsv`)로 변환
    - `00_...` 스크립트로 Bareun 서버에 신규 사전 업로드

- **(2차 분석)**
    - `02_0...` 스크립트를 **다시 실행**하되, 이번에는 새로 업로드한 사용자 사전을 선택

- **결과**: "머신러닝 기반"과 같은 복합어가 하나의 명사로 인식되어 분석의 질적 향상

---

# 결론 및 Q&A

## Key Takeaways
- N-gram, PMI 등 통계적 방법과 분석가의 수동 검토를 결합하는 것이 복합어 처리의 효과적인 전략
- 사용자 사전은 도메인 특화 분석의 핵심 기능

## Q&A
